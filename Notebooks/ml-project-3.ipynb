{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bdf9c56",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-26T22:45:55.241077Z",
     "iopub.status.busy": "2024-11-26T22:45:55.240738Z",
     "iopub.status.idle": "2024-11-26T22:45:55.540892Z",
     "shell.execute_reply": "2024-11-26T22:45:55.539987Z"
    },
    "papermill": {
     "duration": 0.306216,
     "end_time": "2024-11-26T22:45:55.542690",
     "exception": false,
     "start_time": "2024-11-26T22:45:55.236474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/brats20-dataset-training-validation\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "dataset_path = kagglehub.dataset_download(\"awsaf49/brats20-dataset-training-validation\")\n",
    "print(\"Path to dataset files:\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606b5e1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T22:45:55.548940Z",
     "iopub.status.busy": "2024-11-26T22:45:55.548687Z",
     "iopub.status.idle": "2024-11-26T22:46:02.416573Z",
     "shell.execute_reply": "2024-11-26T22:46:02.415706Z"
    },
    "papermill": {
     "duration": 6.873037,
     "end_time": "2024-11-26T22:46:02.418442",
     "exception": false,
     "start_time": "2024-11-26T22:45:55.545405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "print(\"Random seed set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978b6728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T22:46:02.424696Z",
     "iopub.status.busy": "2024-11-26T22:46:02.424278Z",
     "iopub.status.idle": "2024-11-26T22:46:02.432524Z",
     "shell.execute_reply": "2024-11-26T22:46:02.431829Z"
    },
    "papermill": {
     "duration": 0.013019,
     "end_time": "2024-11-26T22:46:02.433995",
     "exception": false,
     "start_time": "2024-11-26T22:46:02.420976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MRISegDataset(Dataset):\n",
    "    def __init__(self, base_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            base_path (str): Path to the dataset folder.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.base_path = base_path\n",
    "        self.patients = [p for p in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, p))]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.patients)*155\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index of the patient to fetch data for.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing 'image', 'segmentation', and optionally 'patient_id'.\n",
    "        \"\"\"\n",
    "        patient_id = self.patients[ind//155]\n",
    "        if patient_id == 'BraTS20_Training_355': \n",
    "            flair_path = os.path.join(self.base_path, patient_id, \"W39_1998.09.19_Segm.nii\")\n",
    "            seg_path = os.path.join(self.base_path, patient_id, \"W39_1998.09.19_Segm.nii\")\n",
    "        else:\n",
    "            flair_path = os.path.join(self.base_path, patient_id, f\"{patient_id}_flair.nii\")\n",
    "            seg_path = os.path.join(self.base_path, patient_id, f\"{patient_id}_seg.nii\")\n",
    "\n",
    "        flair = nib.load(flair_path).get_fdata()[:, :, ind%155].reshape(1, 240, 240)\n",
    "        seg = nib.load(seg_path).get_fdata()[:, :, ind%155].reshape(1, 240, 240)\n",
    "        seg = np.where(seg==4, 3, seg)\n",
    "\n",
    "        # Normalization\n",
    "        flair = (flair - 0) / (900 - 0)\n",
    "\n",
    "        flair = torch.tensor(flair, dtype=torch.float32)\n",
    "        seg = torch.tensor(seg, dtype=torch.long)\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            flair = self.transform(flair)\n",
    "            seg = self.transform(seg)\n",
    "\n",
    "        sample = {'image': flair, 'segmentation': seg, 'patient_id': patient_id}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ab4b05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T22:46:02.439680Z",
     "iopub.status.busy": "2024-11-26T22:46:02.439441Z",
     "iopub.status.idle": "2024-11-26T22:46:03.157162Z",
     "shell.execute_reply": "2024-11-26T22:46:03.155882Z"
    },
    "papermill": {
     "duration": 0.722838,
     "end_time": "2024-11-26T22:46:03.159233",
     "exception": false,
     "start_time": "2024-11-26T22:46:02.436395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 256, 256])\n",
      "Segmentation shape: torch.Size([1, 256, 256])\n",
      "Patient ID: BraTS20_Training_083\n"
     ]
    }
   ],
   "source": [
    "base_path = dataset_path +'/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
    "brats_dataset = MRISegDataset(base_path=base_path, transform=transforms.Resize((256, 256)))\n",
    "\n",
    "# Example: Access a single sample\n",
    "sample = brats_dataset[0]\n",
    "print(\"Image shape:\", sample['image'].shape)\n",
    "print(\"Segmentation shape:\", sample['segmentation'].shape)\n",
    "print(\"Patient ID:\", sample['patient_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949ed741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T22:46:03.167701Z",
     "iopub.status.busy": "2024-11-26T22:46:03.166895Z",
     "iopub.status.idle": "2024-11-26T22:46:03.172669Z",
     "shell.execute_reply": "2024-11-26T22:46:03.171857Z"
    },
    "papermill": {
     "duration": 0.011695,
     "end_time": "2024-11-26T22:46:03.174470",
     "exception": false,
     "start_time": "2024-11-26T22:46:03.162775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(pred, target, smooth=1e-6):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "\n",
    "    pred_class_all = torch.argmax(pred, dim=1)\n",
    "    \n",
    "    dice_total = []\n",
    "    for class_ind in range(4):\n",
    "        pred_class = (pred_class_all == class_ind).float()\n",
    "        target_class = (target == class_ind).float()\n",
    "        \n",
    "        intersection = (pred_class * target_class).sum(dim=(1,2))\n",
    "        union = pred_class.sum(dim=(1,2)) + target_class.sum(dim=(1,2))\n",
    "        \n",
    "        dice_class = (2. * intersection + smooth) / (union + smooth)\n",
    "        dice_total.append(dice_class)\n",
    "    \n",
    "    return torch.mean(torch.stack(dice_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d5490f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T22:46:03.181836Z",
     "iopub.status.busy": "2024-11-26T22:46:03.181583Z",
     "iopub.status.idle": "2024-11-26T22:46:03.186146Z",
     "shell.execute_reply": "2024-11-26T22:46:03.185184Z"
    },
    "papermill": {
     "duration": 0.010027,
     "end_time": "2024-11-26T22:46:03.187725",
     "exception": false,
     "start_time": "2024-11-26T22:46:03.177698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Currently using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1cb1bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T22:46:03.194564Z",
     "iopub.status.busy": "2024-11-26T22:46:03.194324Z",
     "iopub.status.idle": "2024-11-26T22:46:03.214584Z",
     "shell.execute_reply": "2024-11-26T22:46:03.213618Z"
    },
    "papermill": {
     "duration": 0.025242,
     "end_time": "2024-11-26T22:46:03.216440",
     "exception": false,
     "start_time": "2024-11-26T22:46:03.191198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet_Res(\n",
      "  (enc1): ResBlock(\n",
      "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (skip): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (enc2): ResBlock(\n",
      "    (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (skip): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bottleneck): ResBlock(\n",
      "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (skip): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (up2): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (dec2): ResBlock(\n",
      "    (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (skip): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (up1): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (dec1): ResBlock(\n",
      "    (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (skip): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (final_conv): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Total trainable parameters: 80,020\n"
     ]
    }
   ],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.skip = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)  # Match dimensions\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        out = torch.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out += identity # Reisdual connection\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNet_Res(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet_Res, self).__init__()\n",
    "\n",
    "        self.enc1 = ResBlock(1, 16)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc2 = ResBlock(16, 32)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = ResBlock(32, 32)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2)\n",
    "        self.dec2 = ResBlock(64, 32)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
    "        self.dec1 = ResBlock(32, 16)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(16, 4, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        enc1_pool = self.pool1(enc1)\n",
    "\n",
    "        enc2 = self.enc2(enc1_pool)\n",
    "        enc2_pool = self.pool2(enc2)\n",
    "\n",
    "        bottleneck = self.bottleneck(enc2_pool)\n",
    "\n",
    "        up2 = self.up2(bottleneck)\n",
    "        dec2 = self.dec2(torch.cat([up2, enc2], dim=1))\n",
    "\n",
    "        up1 = self.up1(dec2)\n",
    "        dec1 = self.dec1(torch.cat([up1, enc1], dim=1))\n",
    "\n",
    "        out = self.final_conv(dec1)\n",
    "        return out\n",
    "\n",
    "\n",
    "tmp_model = UNet_Res()\n",
    "\n",
    "print(tmp_model)\n",
    "print(f\"Total trainable parameters: {sum(p.numel() for p in tmp_model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e06447c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T22:46:03.224038Z",
     "iopub.status.busy": "2024-11-26T22:46:03.223800Z",
     "iopub.status.idle": "2024-11-26T22:46:03.393534Z",
     "shell.execute_reply": "2024-11-26T22:46:03.392681Z"
    },
    "papermill": {
     "duration": 0.175376,
     "end_time": "2024-11-26T22:46:03.395184",
     "exception": false,
     "start_time": "2024-11-26T22:46:03.219808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches: 3575\n",
      "Moved to cuda.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "data_loader = DataLoader(brats_dataset, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                         num_workers=2)\n",
    "print(f\"Number of Batches: {len(data_loader)}\")\n",
    "\n",
    "model_res = UNet_Res()\n",
    "if torch.cuda.is_available(): \n",
    "    model_res = model_res.cuda()\n",
    "    print(\"Moved to cuda.\")\n",
    "criterion_res = nn.CrossEntropyLoss()\n",
    "optimizer_res = torch.optim.Adam(model_res.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5872d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T22:46:03.401633Z",
     "iopub.status.busy": "2024-11-26T22:46:03.401373Z",
     "iopub.status.idle": "2024-11-27T01:04:36.051461Z",
     "shell.execute_reply": "2024-11-27T01:04:36.050520Z"
    },
    "papermill": {
     "duration": 8312.660987,
     "end_time": "2024-11-27T01:04:36.058944",
     "exception": false,
     "start_time": "2024-11-26T22:46:03.397957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/3575, Time: 1.3007, Loss: 1.3038\n",
      "Batch 300/3575, Time: 0.2631, Loss: 0.0381\n",
      "Batch 600/3575, Time: 0.3565, Loss: 0.0603\n",
      "Batch 900/3575, Time: 0.2623, Loss: 0.0437\n",
      "Batch 1200/3575, Time: 0.3594, Loss: 0.0540\n",
      "Batch 1500/3575, Time: 0.2623, Loss: 0.0625\n",
      "Batch 1800/3575, Time: 0.3297, Loss: 0.0189\n",
      "Batch 2100/3575, Time: 0.3563, Loss: 0.0305\n",
      "Batch 2400/3575, Time: 0.2605, Loss: 0.0394\n",
      "Batch 2700/3575, Time: 0.3653, Loss: 0.0437\n",
      "Batch 3000/3575, Time: 0.3495, Loss: 0.0189\n",
      "Batch 3300/3575, Time: 0.2634, Loss: 0.0739\n",
      "Epoch 1/5, Time: 1705.4893, Loss: 0.0484\n",
      "Saving weights\n",
      "Batch 0/3575, Time: 0.3759, Loss: 0.0680\n",
      "Batch 300/3575, Time: 0.3739, Loss: 0.0080\n",
      "Batch 600/3575, Time: 0.3719, Loss: 0.0357\n",
      "Batch 900/3575, Time: 0.3745, Loss: 0.0274\n",
      "Batch 1200/3575, Time: 0.3608, Loss: 0.0291\n",
      "Batch 1500/3575, Time: 0.3654, Loss: 0.0247\n",
      "Batch 1800/3575, Time: 0.3700, Loss: 0.0408\n",
      "Batch 2100/3575, Time: 0.3205, Loss: 0.0485\n",
      "Batch 2400/3575, Time: 0.2669, Loss: 0.0259\n",
      "Batch 2700/3575, Time: 0.2920, Loss: 0.0372\n",
      "Batch 3000/3575, Time: 0.3668, Loss: 0.0166\n",
      "Batch 3300/3575, Time: 0.3653, Loss: 0.0160\n",
      "Epoch 2/5, Time: 1650.7269, Loss: 0.0323\n",
      "Saving weights\n",
      "Batch 0/3575, Time: 0.4217, Loss: 0.0244\n",
      "Batch 300/3575, Time: 0.3603, Loss: 0.0472\n",
      "Batch 600/3575, Time: 0.2697, Loss: 0.0281\n",
      "Batch 900/3575, Time: 0.2866, Loss: 0.0638\n",
      "Batch 1200/3575, Time: 0.3641, Loss: 0.0215\n",
      "Batch 1500/3575, Time: 0.2615, Loss: 0.0286\n",
      "Batch 1800/3575, Time: 0.2638, Loss: 0.0365\n",
      "Batch 2100/3575, Time: 0.3710, Loss: 0.0155\n",
      "Batch 2400/3575, Time: 0.2649, Loss: 0.0245\n",
      "Batch 2700/3575, Time: 0.3074, Loss: 0.0401\n",
      "Batch 3000/3575, Time: 0.3667, Loss: 0.0183\n",
      "Batch 3300/3575, Time: 0.2641, Loss: 0.0300\n",
      "Epoch 3/5, Time: 1649.2849, Loss: 0.0291\n",
      "Saving weights\n",
      "Batch 0/3575, Time: 0.3678, Loss: 0.0237\n",
      "Batch 300/3575, Time: 0.2685, Loss: 0.0296\n",
      "Batch 600/3575, Time: 0.3293, Loss: 0.0184\n",
      "Batch 900/3575, Time: 0.3688, Loss: 0.0276\n",
      "Batch 1200/3575, Time: 0.3305, Loss: 0.0307\n",
      "Batch 1500/3575, Time: 0.3107, Loss: 0.0363\n",
      "Batch 1800/3575, Time: 0.3647, Loss: 0.0173\n",
      "Batch 2100/3575, Time: 0.3593, Loss: 0.0317\n",
      "Batch 2400/3575, Time: 0.3406, Loss: 0.0198\n",
      "Batch 2700/3575, Time: 0.2643, Loss: 0.0265\n",
      "Batch 3000/3575, Time: 0.3601, Loss: 0.0121\n",
      "Batch 3300/3575, Time: 0.3663, Loss: 0.0149\n",
      "Epoch 4/5, Time: 1653.4244, Loss: 0.0270\n",
      "Saving weights\n",
      "Batch 0/3575, Time: 0.5410, Loss: 0.0333\n",
      "Batch 300/3575, Time: 0.2988, Loss: 0.0289\n",
      "Batch 600/3575, Time: 0.2670, Loss: 0.0261\n",
      "Batch 900/3575, Time: 0.2685, Loss: 0.0086\n",
      "Batch 1200/3575, Time: 0.3668, Loss: 0.0260\n",
      "Batch 1500/3575, Time: 0.2683, Loss: 0.0300\n",
      "Batch 1800/3575, Time: 0.3367, Loss: 0.0312\n",
      "Batch 2100/3575, Time: 0.2713, Loss: 0.0291\n",
      "Batch 2400/3575, Time: 0.2717, Loss: 0.0266\n",
      "Batch 2700/3575, Time: 0.2685, Loss: 0.0432\n",
      "Batch 3000/3575, Time: 0.3264, Loss: 0.0279\n",
      "Batch 3300/3575, Time: 0.2971, Loss: 0.0398\n",
      "Epoch 5/5, Time: 1653.6930, Loss: 0.0257\n",
      "Saving weights\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "training_losses = []\n",
    "epoch_times = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    model_res.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        batch_start_time = time.time()\n",
    "        images = batch['image'].to(device) \n",
    "        segmentations = batch['segmentation'].squeeze(1).to(device)\n",
    "\n",
    "        optimizer_res.zero_grad()\n",
    "    \n",
    "        outputs = model_res(images)\n",
    "        loss = criterion_res(outputs, segmentations)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_res.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        del images\n",
    "        del segmentations\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        if batch_idx%300 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(data_loader)}, Time: {time.time()-batch_start_time:.4f}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    epoch_time = time.time()-epoch_start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.4f}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"Saving weights\")\n",
    "    torch.save(model_res.state_dict(), f\"UNet3_weights_{epoch}.pth\")\n",
    "    training_losses.append(avg_loss)\n",
    "    epoch_times.append(epoch_time)\n",
    "    \n",
    "with open(\"UNet3.txt\", \"w\") as f:\n",
    "    f.write(\"Training_losses: \\n\")\n",
    "    for i in training_losses: f.write(str(i)+\"\\n\")\n",
    "    f.write(\"\\nEpoch_times: \\n\")\n",
    "    for i in epoch_times: f.write(str(i)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef04b16",
   "metadata": {
    "papermill": {
     "duration": 0.00503,
     "end_time": "2024-11-27T01:04:36.069293",
     "exception": false,
     "start_time": "2024-11-27T01:04:36.064263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 751906,
     "sourceId": 1299795,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8325.530788,
   "end_time": "2024-11-27T01:04:38.376546",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-26T22:45:52.845758",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
