{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d950dbe",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-27T01:47:47.874851Z",
     "iopub.status.busy": "2024-11-27T01:47:47.874478Z",
     "iopub.status.idle": "2024-11-27T01:47:48.145787Z",
     "shell.execute_reply": "2024-11-27T01:47:48.144879Z"
    },
    "papermill": {
     "duration": 0.27834,
     "end_time": "2024-11-27T01:47:48.147814",
     "exception": false,
     "start_time": "2024-11-27T01:47:47.869474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/brats20-dataset-training-validation\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "dataset_path = kagglehub.dataset_download(\"awsaf49/brats20-dataset-training-validation\")\n",
    "print(\"Path to dataset files:\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "badc998b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:47:48.155731Z",
     "iopub.status.busy": "2024-11-27T01:47:48.154987Z",
     "iopub.status.idle": "2024-11-27T01:47:55.744871Z",
     "shell.execute_reply": "2024-11-27T01:47:55.743744Z"
    },
    "papermill": {
     "duration": 7.595771,
     "end_time": "2024-11-27T01:47:55.746798",
     "exception": false,
     "start_time": "2024-11-27T01:47:48.151027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "print(\"Random seed set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d364b42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:47:55.754033Z",
     "iopub.status.busy": "2024-11-27T01:47:55.753552Z",
     "iopub.status.idle": "2024-11-27T01:47:55.762123Z",
     "shell.execute_reply": "2024-11-27T01:47:55.761190Z"
    },
    "papermill": {
     "duration": 0.014243,
     "end_time": "2024-11-27T01:47:55.763934",
     "exception": false,
     "start_time": "2024-11-27T01:47:55.749691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MRISegDataset(Dataset):\n",
    "    def __init__(self, base_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            base_path (str): Path to the dataset folder.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.base_path = base_path\n",
    "        self.patients = [p for p in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, p))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.patients)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index of the patient to fetch data for.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing 'image', 'segmentation', and optionally 'patient_id'.\n",
    "        \"\"\"\n",
    "        patient_id = self.patients[ind]\n",
    "        if patient_id == 'BraTS20_Training_355': \n",
    "            flair_path = os.path.join(self.base_path, patient_id, \"W39_1998.09.19_Segm.nii\")\n",
    "            seg_path = os.path.join(self.base_path, patient_id, \"W39_1998.09.19_Segm.nii\")\n",
    "        else:\n",
    "            flair_path = os.path.join(self.base_path, patient_id, f\"{patient_id}_flair.nii\")\n",
    "            seg_path = os.path.join(self.base_path, patient_id, f\"{patient_id}_seg.nii\")\n",
    "\n",
    "        flair = nib.load(flair_path).get_fdata()\n",
    "        seg = nib.load(seg_path).get_fdata()\n",
    "        seg = np.where(seg==4, 3, seg)\n",
    "\n",
    "        # Normalization\n",
    "        flair = (flair - 0) / (900 - 0)\n",
    "\n",
    "        flair = torch.tensor(flair, dtype=torch.float32).unsqueeze(0)\n",
    "        seg = torch.tensor(seg, dtype=torch.long)\n",
    "\n",
    "        sample = {'image': flair, 'segmentation': seg, 'patient_id': patient_id}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bafe0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:47:55.770879Z",
     "iopub.status.busy": "2024-11-27T01:47:55.770581Z",
     "iopub.status.idle": "2024-11-27T01:47:56.670040Z",
     "shell.execute_reply": "2024-11-27T01:47:56.668993Z"
    },
    "papermill": {
     "duration": 0.905293,
     "end_time": "2024-11-27T01:47:56.672242",
     "exception": false,
     "start_time": "2024-11-27T01:47:55.766949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 240, 240, 155])\n",
      "Segmentation shape: torch.Size([240, 240, 155])\n",
      "Patient ID: BraTS20_Training_083\n"
     ]
    }
   ],
   "source": [
    "base_path = dataset_path +'/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
    "brats_dataset = MRISegDataset(base_path=base_path)\n",
    "\n",
    "# Example: Access a single sample\n",
    "sample = brats_dataset[0]\n",
    "print(\"Image shape:\", sample['image'].shape)\n",
    "print(\"Segmentation shape:\", sample['segmentation'].shape)\n",
    "print(\"Patient ID:\", sample['patient_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05e8e38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:47:56.680403Z",
     "iopub.status.busy": "2024-11-27T01:47:56.679578Z",
     "iopub.status.idle": "2024-11-27T01:47:56.686428Z",
     "shell.execute_reply": "2024-11-27T01:47:56.685477Z"
    },
    "papermill": {
     "duration": 0.012982,
     "end_time": "2024-11-27T01:47:56.688473",
     "exception": false,
     "start_time": "2024-11-27T01:47:56.675491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(pred, target, smooth=1e-6):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "\n",
    "    pred_class_all = torch.argmax(pred, dim=1)\n",
    "    \n",
    "    dice_total = []\n",
    "    for class_ind in range(4):\n",
    "        pred_class = (pred_class_all == class_ind).float()\n",
    "        target_class = (target == class_ind).float()\n",
    "        \n",
    "        intersection = (pred_class * target_class).sum(dim=(1,2))\n",
    "        union = pred_class.sum(dim=(1,2)) + target_class.sum(dim=(1,2))\n",
    "        \n",
    "        dice_class = (2. * intersection + smooth) / (union + smooth)\n",
    "        dice_total.append(dice_class)\n",
    "    \n",
    "    return torch.mean(torch.stack(dice_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f107a456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:47:56.698479Z",
     "iopub.status.busy": "2024-11-27T01:47:56.697851Z",
     "iopub.status.idle": "2024-11-27T01:47:56.703433Z",
     "shell.execute_reply": "2024-11-27T01:47:56.702371Z"
    },
    "papermill": {
     "duration": 0.012842,
     "end_time": "2024-11-27T01:47:56.705570",
     "exception": false,
     "start_time": "2024-11-27T01:47:56.692728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Currently using: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224a0a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:47:56.714765Z",
     "iopub.status.busy": "2024-11-27T01:47:56.713869Z",
     "iopub.status.idle": "2024-11-27T01:47:56.734489Z",
     "shell.execute_reply": "2024-11-27T01:47:56.733064Z"
    },
    "papermill": {
     "duration": 0.02687,
     "end_time": "2024-11-27T01:47:56.736678",
     "exception": false,
     "start_time": "2024-11-27T01:47:56.709808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv3D(\n",
      "  (conv1): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv2): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv3): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv4): Conv3d(16, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Total trainable parameters: 29,876\n"
     ]
    }
   ],
   "source": [
    "class Conv3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 16, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv3d(16, 4, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.conv4(x)\n",
    "        return x\n",
    "\n",
    "model_3d = Conv3D()\n",
    "print(model_3d)\n",
    "print(f\"Total trainable parameters: {sum(p.numel() for p in model_3d.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e9329b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:47:56.747324Z",
     "iopub.status.busy": "2024-11-27T01:47:56.746612Z",
     "iopub.status.idle": "2024-11-27T01:47:56.925122Z",
     "shell.execute_reply": "2024-11-27T01:47:56.924052Z"
    },
    "papermill": {
     "duration": 0.185802,
     "end_time": "2024-11-27T01:47:56.927005",
     "exception": false,
     "start_time": "2024-11-27T01:47:56.741203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches: 185\n",
      "Moved to cuda.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "data_loader = DataLoader(brats_dataset, batch_size=batch_size, shuffle=True, pin_memory=True,\n",
    "                         num_workers=2)\n",
    "print(f\"Number of Batches: {len(data_loader)}\")\n",
    "\n",
    "model_3d = Conv3D()\n",
    "if torch.cuda.is_available(): \n",
    "    model_3d = model_3d.cuda()\n",
    "    print(\"Moved to cuda.\")\n",
    "criterion_3d = nn.CrossEntropyLoss()\n",
    "optimizer_3d = torch.optim.Adam(model_3d.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a738a73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T01:47:56.934848Z",
     "iopub.status.busy": "2024-11-27T01:47:56.934301Z",
     "iopub.status.idle": "2024-11-27T02:19:16.546672Z",
     "shell.execute_reply": "2024-11-27T02:19:16.545550Z"
    },
    "papermill": {
     "duration": 1879.62229,
     "end_time": "2024-11-27T02:19:16.552451",
     "exception": false,
     "start_time": "2024-11-27T01:47:56.930161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/185, Time: 3.8468, Loss: 1.3738\n",
      "Epoch 1/5, Time: 378.7881, Loss: 0.1367\n",
      "Saving weights\n",
      "Batch 0/185, Time: 2.1009, Loss: 0.0526\n",
      "Epoch 2/5, Time: 374.6736, Loss: 0.0491\n",
      "Saving weights\n",
      "Batch 0/185, Time: 2.0959, Loss: 0.0434\n",
      "Epoch 3/5, Time: 375.2402, Loss: 0.0480\n",
      "Saving weights\n",
      "Batch 0/185, Time: 2.0961, Loss: 0.0529\n",
      "Epoch 4/5, Time: 375.6489, Loss: 0.0484\n",
      "Saving weights\n",
      "Batch 0/185, Time: 2.1073, Loss: 0.0380\n",
      "Epoch 5/5, Time: 375.2379, Loss: 0.0494\n",
      "Saving weights\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "training_losses = []\n",
    "epoch_times = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    model_3d.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        batch_start_time = time.time()\n",
    "        images = batch['image'].to(device) \n",
    "        segmentations = batch['segmentation'].squeeze(1).to(device)\n",
    "\n",
    "        optimizer_3d.zero_grad()\n",
    "    \n",
    "        outputs = model_3d(images)\n",
    "        loss = criterion_3d(outputs, segmentations)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_3d.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        del images\n",
    "        del segmentations\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        if batch_idx%300 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(data_loader)}, Time: {time.time()-batch_start_time:.4f}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    epoch_time = time.time()-epoch_start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.4f}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"Saving weights\")\n",
    "    torch.save(model_3d.state_dict(), f\"Conv3D_weights_{epoch}.pth\")\n",
    "    training_losses.append(avg_loss)\n",
    "    epoch_times.append(epoch_time)\n",
    "    \n",
    "with open(\"Conv3D.txt\", \"w\") as f:\n",
    "    f.write(\"Training_losses: \\n\")\n",
    "    for i in training_losses: f.write(str(i)+\"\\n\")\n",
    "    f.write(\"\\nEpoch_times: \\n\")\n",
    "    for i in epoch_times: f.write(str(i)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a996f263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T02:19:16.560943Z",
     "iopub.status.busy": "2024-11-27T02:19:16.560585Z",
     "iopub.status.idle": "2024-11-27T02:19:16.884725Z",
     "shell.execute_reply": "2024-11-27T02:19:16.883390Z"
    },
    "papermill": {
     "duration": 0.330524,
     "end_time": "2024-11-27T02:19:16.886594",
     "exception": true,
     "start_time": "2024-11-27T02:19:16.556070",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'UNet2.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUNet2.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     content \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(content)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'UNet2.txt'"
     ]
    }
   ],
   "source": [
    "with open(\"UNet2.txt\", \"r\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e512d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(training_losses)\n",
    "print(training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c86efa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(epoch_times)\n",
    "print(epoch_times)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 1331968,
     "datasetId": 751906,
     "sourceId": 1299795,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1894.660089,
   "end_time": "2024-11-27T02:19:19.714081",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-27T01:47:45.053992",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
